{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SinkhornDistance(torch.nn.Module):\n",
    "    r\"\"\"\n",
    "        Given two empirical measures each with :math:`P_1` locations\n",
    "        :math:`x\\in\\mathbb{R}^{D_1}` and :math:`P_2` locations :math:`y\\in\\mathbb{R}^{D_2}`,\n",
    "        outputs an approximation of the regularized OT cost for point clouds.\n",
    "        Args:\n",
    "        eps (float): regularization coefficient\n",
    "        max_iter (int): maximum number of Sinkhorn iterations\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "        'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "        'mean': the sum of the output will be divided by the number of\n",
    "        elements in the output, 'sum': the output will be summed. Default: 'none'\n",
    "        Shape:\n",
    "            - Input: :math:`(N, P_1, D_1)`, :math:`(N, P_2, D_2)`\n",
    "            - Output: :math:`(N)` or :math:`()`, depending on `reduction`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eps=1e-3, max_iter=100, reduction='none'):\n",
    "        super(SinkhornDistance, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.max_iter = max_iter\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, mu, nu, C):\n",
    "        u = torch.ones_like(mu)\n",
    "        v = torch.ones_like(nu)\n",
    "\n",
    "        # Sinkhorn iterations\n",
    "        for i in range(self.max_iter):\n",
    "            v = self.eps * \\\n",
    "                (torch.log(\n",
    "                    nu + 1e-8) - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)) + v\n",
    "            u = self.eps * \\\n",
    "                (torch.log(\n",
    "                    mu + 1e-8) - torch.logsumexp(self.M(C, u, v), dim=-1)) + u\n",
    "\n",
    "        U, V = u, v\n",
    "        # Transport plan pi = diag(a)*K*diag(b)\n",
    "        pi = torch.exp(\n",
    "            self.M(C, U, V)).detach()\n",
    "        # Sinkhorn distance\n",
    "        cost = torch.sum(\n",
    "            pi * C, dim=(-2, -1))\n",
    "        return cost, pi\n",
    "\n",
    "    def M(self, C, u, v):\n",
    "        '''\n",
    "        \"Modified cost for logarithmic updates\"\n",
    "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / epsilon$\"\n",
    "        '''\n",
    "        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n",
    "\n",
    "def distributed_sinkhorn(out, sinkhorn_iterations=100, epsilon=0.05):\n",
    "    L = torch.exp(out / epsilon).t() # K x B\n",
    "    B = L.shape[1]\n",
    "    K = L.shape[0]\n",
    "\n",
    "    # make the matrix sums to 1\n",
    "    sum_L = torch.sum(L)\n",
    "    L /= sum_L\n",
    "\n",
    "    for _ in range(sinkhorn_iterations):\n",
    "        L /= torch.sum(L, dim=1, keepdim=True)\n",
    "        L /= K\n",
    "\n",
    "        L /= torch.sum(L, dim=0, keepdim=True)\n",
    "        L /= B\n",
    "\n",
    "    L *= B\n",
    "    L = L.t()\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args M, u, v:\n",
      "[[-0.4  0.3 -0.1]\n",
      " [ 0.1  0.4 -0.5]\n",
      " [ 0.   0.2  0.7]]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "--------------emd: pi, cost, sum------------\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "-0.7\n",
      "-0.7\n",
      "--------------sinkhorn: pi, cost, sum------------\n",
      "[[0.39280317 0.28977983 0.317417  ]\n",
      " [0.24461164 0.26920808 0.48618029]\n",
      " [0.3625852  0.44101209 0.19640271]]\n",
      "0.012809550587488963\n",
      "0.012809550587488963\n",
      "--------------dsinkhorn: pi, sum------------\n",
      "tensor([[9.9296e-01, 6.8908e-03, 1.4441e-04],\n",
      "        [1.0448e-04, 2.1614e-03, 9.9773e-01],\n",
      "        [6.4996e-03, 9.9350e-01, 3.1710e-10]], dtype=torch.float64)\n",
      "tensor(-0.6944, dtype=torch.float64)\n",
      "--------------sinkhornd: pi, cost------------\n",
      "tensor([[[ 1.0000e+00,  3.7201e-44, 1.9152e-174],\n",
      "         [7.1246e-218,  1.3839e-87,  1.0000e+00],\n",
      "         [1.9152e-174,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.0000e+00,  3.7201e-44, 1.9152e-174],\n",
      "         [7.1246e-218,  1.3839e-87,  1.0000e+00],\n",
      "         [1.9152e-174,  1.0000e+00,  0.0000e+00]]], dtype=torch.float64)\n",
      "tensor([-0.7000, -0.7000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "first_histogram = np.array([1.0, 1.0, 1.0])\n",
    "second_histogram = np.array([1.0, 1.0, 1.0])\n",
    "cost = np.array([[-0.4, 0.3, -0.1], [0.1, 0.4, -0.5], [0.0, 0.2, 0.7]])\n",
    "\n",
    "print(\"Args M, u, v:\")\n",
    "print(cost)\n",
    "print(first_histogram)\n",
    "print(second_histogram)\n",
    "\n",
    "pi_ot = ot.emd(first_histogram, second_histogram, cost)\n",
    "cost_ot = ot.emd2(first_histogram, second_histogram, cost)\n",
    "\n",
    "print(\"--------------emd: pi, cost, sum------------\")\n",
    "print(pi_ot)\n",
    "print(cost_ot)\n",
    "print((cost*pi_ot).sum())\n",
    "\n",
    "\n",
    "pi_sinkhorn = ot.sinkhorn(first_histogram, second_histogram, cost, reg = 1)\n",
    "cost_sinkhorn = ot.sinkhorn2(first_histogram, second_histogram, cost, reg = 1)\n",
    "print(\"--------------sinkhorn: pi, cost, sum------------\")\n",
    "print(pi_sinkhorn)\n",
    "print(cost_sinkhorn)\n",
    "print((cost*pi_sinkhorn).sum())\n",
    "\n",
    "pi = distributed_sinkhorn(-torch.tensor(cost))\n",
    "print(\"--------------dsinkhorn: pi, sum------------\")\n",
    "print(pi)\n",
    "print((torch.tensor(cost)*pi).sum())\n",
    "\n",
    "first_histogram_pt = torch.tensor(first_histogram)\n",
    "second_histogram_pt = torch.tensor(second_histogram)\n",
    "cost_pt = torch.tensor(cost)\n",
    "# cost_pt.requires_grad=True\n",
    "\n",
    "first_histogram_pt = first_histogram_pt.expand(2, -1)\n",
    "second_histogram_pt = second_histogram_pt.expand(2, -1)\n",
    "cost_pt = cost_pt.expand(2, -1, -1)\n",
    "\n",
    "solver = SinkhornDistance()\n",
    "cost_ot, pi = solver(first_histogram_pt, second_histogram_pt, cost_pt)\n",
    "print(\"--------------sinkhornd: pi, cost------------\")\n",
    "print(pi)\n",
    "print(cost_ot)\n",
    "\n",
    "# first_histogram = np.array([[1.0, 2.5, 1.0], [1.0, 1, 1.0]])\n",
    "# second_histogram = np.array([[1.0, 1.5, 2.0], [1.0, 1, 0.0]])\n",
    "# cost = np.array([[[4.0, 1, 3], [2, 0, 5], [3, 2, 2]],[[2, 1, 3], [2, 2, 0], [3, 2, 2]]])\n",
    "# first_histogram_pt = torch.tensor(first_histogram)\n",
    "# second_histogram_pt = torch.tensor(second_histogram)\n",
    "# cost_pt = torch.tensor(cost)\n",
    "\n",
    "# solver = SinkhornDistance()\n",
    "# cost_ot, pi = solver(first_histogram_pt, second_histogram_pt, cost_pt)\n",
    "# print(pi)\n",
    "# print(cost_ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio = 2992/3000=0.9973333333333333\n",
      "2966.763161420822\n",
      "2968.2905600070953\n",
      "2966.7630803585052\n"
     ]
    }
   ],
   "source": [
    "consist_cnt = 0\n",
    "total_cnt = 0\n",
    "costa = 0\n",
    "costb = 0\n",
    "costc = 0\n",
    "\n",
    "\n",
    "solver = SinkhornDistance(eps=0.05)\n",
    "\n",
    "for _ in range(1000):\n",
    "    protos = torch.randn(4, 768)\n",
    "    hiddens = torch.randn(3, 768)\n",
    "    sim = torch.einsum(\"sd,pd->sp\", F.normalize(hiddens), F.normalize(protos))\n",
    "    cost = 1 - sim\n",
    "    # cost = torch.randint(0, 5, (4, 3)).float()\n",
    "    # print(cost)\n",
    "\n",
    "    res_algo = distributed_sinkhorn(-cost)\n",
    "    # print(res_algo)\n",
    "\n",
    "    n_samples, n_proto = cost.size()\n",
    "    sample_constraint = torch.ones(n_samples, dtype=torch.float)\n",
    "    # proto_constraint = torch.ones(n_proto, dtype=torch.float) / n_proto\n",
    "    proto_constraint = torch.ones(n_proto, dtype=torch.float) * n_samples / n_proto\n",
    "    res_pot = ot.sinkhorn(sample_constraint, proto_constraint, M=cost / abs(cost.max()), reg=0.05, warn=False)\n",
    "    # print(res_pot)\n",
    "\n",
    "    sample_constraint = torch.ones(n_samples, dtype=torch.float)\n",
    "    proto_constraint = torch.ones(n_proto, dtype=torch.float)\n",
    "    _, res_solver = solver(sample_constraint, proto_constraint, cost)\n",
    "\n",
    "    consist_mask = torch.argmax(res_algo, dim=-1) == torch.argmax(res_pot, dim=-1)\n",
    "    consist_cnt += torch.sum(consist_mask).item()\n",
    "    total_cnt += res_algo.size(0)\n",
    "    costa += (res_algo * cost).sum().item()\n",
    "    costb += (res_pot * cost).sum().item()\n",
    "    costc += (res_solver * cost).sum().item()\n",
    "\n",
    "print(\"Ratio = {}/{}={}\".format(consist_cnt, total_cnt, consist_cnt / total_cnt))\n",
    "print(costa)\n",
    "print(costb)\n",
    "print(costc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio = 3000/3000=1.0\n",
      "2978.594125509262\n",
      "2977.6982605457306\n"
     ]
    }
   ],
   "source": [
    "consist_cnt = 0\n",
    "total_cnt = 0\n",
    "costa = 0\n",
    "costb = 0\n",
    "\n",
    "\n",
    "solver = SinkhornDistance(eps=0.05)\n",
    "\n",
    "for _ in range(1000):\n",
    "    protos = torch.randn(4, 768)\n",
    "    ratio = torch.as_tensor([0.7, 0.1, 0.1, 0.1])\n",
    "    hiddens = torch.randn(3, 768)\n",
    "    sim = torch.einsum(\"sd,pd->sp\", F.normalize(hiddens), F.normalize(protos))\n",
    "    cost = 1 - sim\n",
    "    # cost = torch.randint(0, 5, (4, 3)).float()\n",
    "    # print(cost)\n",
    "\n",
    "    n_samples, n_proto = cost.size()\n",
    "    sample_constraint = torch.ones(n_samples, dtype=torch.float)\n",
    "    # proto_constraint = torch.ones(n_proto, dtype=torch.float) / n_proto\n",
    "    proto_constraint = n_samples * ratio\n",
    "    res_pot = ot.sinkhorn(sample_constraint, proto_constraint, M=cost / abs(cost.max()), reg=0.05, warn=False)\n",
    "    # print(res_pot)\n",
    "\n",
    "    _, res_solver = solver(sample_constraint, proto_constraint, cost)\n",
    "\n",
    "    consist_mask = torch.argmax(res_pot, dim=-1) == torch.argmax(res_solver, dim=-1)\n",
    "    consist_cnt += torch.sum(consist_mask).item()\n",
    "    total_cnt += res_pot.size(0)\n",
    "    costa += (res_pot * cost).sum().item()\n",
    "    costb += (res_solver * cost).sum().item()\n",
    "\n",
    "print(\"Ratio = {}/{}={}\".format(consist_cnt, total_cnt, consist_cnt / total_cnt))\n",
    "print(costa)\n",
    "print(costb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('atf-tch182')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59231d05a1207d6d78af635170c80be3311cde855dd08d6da419e74cf0c29f17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
