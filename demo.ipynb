{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SinkhornDistance(torch.nn.Module):\n",
    "    r\"\"\"\n",
    "        Given two empirical measures each with :math:`P_1` locations\n",
    "        :math:`x\\in\\mathbb{R}^{D_1}` and :math:`P_2` locations :math:`y\\in\\mathbb{R}^{D_2}`,\n",
    "        outputs an approximation of the regularized OT cost for point clouds.\n",
    "        Args:\n",
    "        eps (float): regularization coefficient\n",
    "        max_iter (int): maximum number of Sinkhorn iterations\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "        'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "        'mean': the sum of the output will be divided by the number of\n",
    "        elements in the output, 'sum': the output will be summed. Default: 'none'\n",
    "        Shape:\n",
    "            - Input: :math:`(N, P_1, D_1)`, :math:`(N, P_2, D_2)`\n",
    "            - Output: :math:`(N)` or :math:`()`, depending on `reduction`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eps=1e-3, max_iter=100, reduction='none'):\n",
    "        super(SinkhornDistance, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.max_iter = max_iter\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, mu, nu, C):\n",
    "        u = torch.ones_like(mu)\n",
    "        v = torch.ones_like(nu)\n",
    "\n",
    "        # Sinkhorn iterations\n",
    "        for i in range(self.max_iter):\n",
    "            v = self.eps * \\\n",
    "                (torch.log(\n",
    "                    nu + 1e-8) - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)) + v\n",
    "            u = self.eps * \\\n",
    "                (torch.log(\n",
    "                    mu + 1e-8) - torch.logsumexp(self.M(C, u, v), dim=-1)) + u\n",
    "\n",
    "        U, V = u, v\n",
    "        # Transport plan pi = diag(a)*K*diag(b)\n",
    "        pi = torch.exp(\n",
    "            self.M(C, U, V)).detach()\n",
    "        # Sinkhorn distance\n",
    "        cost = torch.sum(\n",
    "            pi * C, dim=(-2, -1))\n",
    "        return cost, pi\n",
    "\n",
    "    def M(self, C, u, v):\n",
    "        '''\n",
    "        \"Modified cost for logarithmic updates\"\n",
    "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / epsilon$\"\n",
    "        '''\n",
    "        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n",
    "\n",
    "def distributed_sinkhorn(out, sinkhorn_iterations=100, epsilon=0.05):\n",
    "    L = torch.exp(out / epsilon).t() # K x B\n",
    "    B = L.shape[1]\n",
    "    K = L.shape[0]\n",
    "\n",
    "    # make the matrix sums to 1\n",
    "    sum_L = torch.sum(L)\n",
    "    L /= sum_L\n",
    "\n",
    "    for _ in range(sinkhorn_iterations):\n",
    "        L /= torch.sum(L, dim=1, keepdim=True)\n",
    "        L /= K\n",
    "\n",
    "        L /= torch.sum(L, dim=0, keepdim=True)\n",
    "        L /= B\n",
    "\n",
    "    L *= B\n",
    "    L = L.t()\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args M, u, v:\n",
      "[[4. 1. 3.]\n",
      " [2. 0. 5.]\n",
      " [3. 2. 2.]]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "--------------emd: pi, cost, sum------------\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "5.0\n",
      "5.0\n",
      "--------------sinkhorn: pi, cost, sum------------\n",
      "[[0.18340519 0.44219386 0.37440095]\n",
      " [0.51965476 0.46091571 0.01942953]\n",
      " [0.29694005 0.09689043 0.60616952]]\n",
      "5.732414695260431\n",
      "5.732414695260431\n",
      "--------------dsinkhorn: pi, sum------------\n",
      "tensor([[1.9952e-07, 9.8983e-01, 1.0174e-02],\n",
      "        [9.8988e-01, 1.0122e-02, 9.1099e-31],\n",
      "        [1.9611e-05, 4.1333e-16, 9.9998e-01]], dtype=torch.float64)\n",
      "tensor(5.0001, dtype=torch.float64)\n",
      "--------------sinkhornd: pi, cost------------\n",
      "tensor([[[0.0000, 0.9898, 0.0102],\n",
      "         [0.9899, 0.0101, 0.0000],\n",
      "         [0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "        [[0.0000, 0.9898, 0.0102],\n",
      "         [0.9899, 0.0101, 0.0000],\n",
      "         [0.0000, 0.0000, 1.0000]]], dtype=torch.float64)\n",
      "tensor([5.0001, 5.0001], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "first_histogram = np.array([1.0, 1.0, 1.0])\n",
    "second_histogram = np.array([1.0, 1.0, 1.0])\n",
    "cost = np.array([[4.0, 1, 3], [2, 0, 5], [3, 2, 2]])\n",
    "\n",
    "print(\"Args M, u, v:\")\n",
    "print(cost)\n",
    "print(first_histogram)\n",
    "print(second_histogram)\n",
    "\n",
    "pi_ot = ot.emd(first_histogram, second_histogram, cost)\n",
    "cost_ot = ot.emd2(first_histogram, second_histogram, cost)\n",
    "\n",
    "print(\"--------------emd: pi, cost, sum------------\")\n",
    "print(pi_ot)\n",
    "print(cost_ot)\n",
    "print((cost*pi_ot).sum())\n",
    "\n",
    "\n",
    "pi_sinkhorn = ot.sinkhorn(first_histogram, second_histogram, cost, reg = 1)\n",
    "cost_sinkhorn = ot.sinkhorn2(first_histogram, second_histogram, cost, reg = 1)\n",
    "print(\"--------------sinkhorn: pi, cost, sum------------\")\n",
    "print(pi_sinkhorn)\n",
    "print(cost_sinkhorn)\n",
    "print((cost*pi_sinkhorn).sum())\n",
    "\n",
    "pi = distributed_sinkhorn(-torch.tensor(cost))\n",
    "print(\"--------------dsinkhorn: pi, sum------------\")\n",
    "print(pi)\n",
    "print((torch.tensor(cost)*pi).sum())\n",
    "\n",
    "first_histogram_pt = torch.tensor(first_histogram)\n",
    "second_histogram_pt = torch.tensor(second_histogram)\n",
    "cost_pt = torch.tensor(cost)\n",
    "# cost_pt.requires_grad=True\n",
    "\n",
    "first_histogram_pt = first_histogram_pt.expand(2, -1)\n",
    "second_histogram_pt = second_histogram_pt.expand(2, -1)\n",
    "cost_pt = cost_pt.expand(2, -1, -1)\n",
    "\n",
    "solver = SinkhornDistance()\n",
    "cost_ot, pi = solver(first_histogram_pt, second_histogram_pt, cost_pt)\n",
    "print(\"--------------sinkhornd: pi, cost------------\")\n",
    "print(pi)\n",
    "print(cost_ot)\n",
    "\n",
    "# first_histogram = np.array([[1.0, 2.5, 1.0], [1.0, 1, 1.0]])\n",
    "# second_histogram = np.array([[1.0, 1.5, 2.0], [1.0, 1, 0.0]])\n",
    "# cost = np.array([[[4.0, 1, 3], [2, 0, 5], [3, 2, 2]],[[2, 1, 3], [2, 2, 0], [3, 2, 2]]])\n",
    "# first_histogram_pt = torch.tensor(first_histogram)\n",
    "# second_histogram_pt = torch.tensor(second_histogram)\n",
    "# cost_pt = torch.tensor(cost)\n",
    "\n",
    "# solver = SinkhornDistance()\n",
    "# cost_ot, pi = solver(first_histogram_pt, second_histogram_pt, cost_pt)\n",
    "# print(pi)\n",
    "# print(cost_ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio = 2993/3000=0.9976666666666667\n",
      "2966.9846572875977\n",
      "2968.5397703647614\n"
     ]
    }
   ],
   "source": [
    "consist_cnt = 0\n",
    "total_cnt = 0\n",
    "costa = 0\n",
    "costb = 0\n",
    "for _ in range(1000):\n",
    "    protos = torch.randn(4, 768)\n",
    "    hiddens = torch.randn(3, 768)\n",
    "    sim = torch.einsum(\"sd,pd->sp\", F.normalize(hiddens), F.normalize(protos))\n",
    "    cost = 1 - sim\n",
    "    # cost = torch.randint(0, 5, (4, 3)).float()\n",
    "    # print(cost)\n",
    "\n",
    "    res_algo = distributed_sinkhorn(-cost)\n",
    "    # print(res_algo)\n",
    "\n",
    "    n_samples, n_proto = cost.size()\n",
    "    sample_constraint = torch.ones(n_samples, dtype=torch.float)\n",
    "    proto_constraint = torch.ones(n_proto, dtype=torch.float) * n_samples / n_proto\n",
    "    res_pot = ot.sinkhorn(sample_constraint, proto_constraint, M=cost / cost.max(), reg=0.05, warn=False)\n",
    "    # print(res_pot)\n",
    "\n",
    "    consist_mask = torch.argmax(res_algo, dim=-1) == torch.argmax(res_pot, dim=-1)\n",
    "    consist_cnt += torch.sum(consist_mask).item()\n",
    "    total_cnt += res_algo.size(0)\n",
    "    costa += (res_algo * cost).sum().item()\n",
    "    costb += (res_pot * cost).sum().item()\n",
    "\n",
    "print(\"Ratio = {}/{}={}\".format(consist_cnt, total_cnt, consist_cnt / total_cnt))\n",
    "print(costa)\n",
    "print(costb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('atf-tch182')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59231d05a1207d6d78af635170c80be3311cde855dd08d6da419e74cf0c29f17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
